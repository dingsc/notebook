# notebook
#算法和机器学习准备
##工作岗位：算法，机器学习工程师。
理由：研究生阶段一直是做机器学习理论方向，不考虑其他则比较合适的是继续学校做研究或者公司AIlab做研究。但研究水平不够，兴趣不大，因而不适合。对编程放的太久，C++和Java基本不熟悉。网络，操作系统已然忘得很干净。合适的是数据方向，算法方向，机器学习方向。其中数据方向大多需要大型平台超大数据的经验。（）。算法和机器学习是主方向。只考虑技术类，其他产品，运营暂不会考虑。AI方向依旧有很大发展前景，但是AI重在质量，不在数量。

计算机基础：编程语言和工具，数据结构，算法。及需要的基础，云计算需要的计算机网络，机器学习需要的统计概率优化等数学基础。不求都突出，但要没有大的不足。
机器学习基础：考虑具体的研究方向，待完成。
###扎实的理论知识，coding，项目，比赛，工程。

1.编程语言:C/C++,python
工具：VSCode+ \<br>

2.编程能力：练，总结
3.算法：练，总结
4.机器学习；思考，记录，总结

C：C程序设计语言，第2版，机械工业出版社。
类型，运算符与表达式
控制
函数
C预处理器：#include，#define
指针和数组
结构
输入输出


4.机器学习基础：

    决策树
    随机森林
    Adaboost
    GBDT
    logistic 回归
    SVM支持向量机
    朴素贝叶斯
    xgboost
    lightgbm 
决策树：原理,ID3,C4.5和CART（二叉树）
    特征选择：信息增益（ID3），信息增益率（C4.5），基尼指数（CART）
    决策树生成
    决策树剪枝


回归树（使用平方误差最小化来选择特征并进行划分，仅限CART算法。预测值为该节点下所有样本值得平均。遍历特征和阈值进行选择）与分类树()

面经

    1.GBDT为什么是在拟合前面几轮的残差？请公式推导。用回归树推导。
    2.SVM为什么要比GBDT好？（这个问题有点奇怪，但是面试官真的是这么问的(微笑脸)，因为我简历里写了用SVM做分类，面试官就问为什么不用GBDT，SVM比GBDT好在哪里？……）这个问题我至今不知道答案，请大神赐教。
    3.GBDT和LR的差别。(这个问题可以推广的，和AdaBoost、RF、XgBoost,etc的差别)
    4.在你所知的算法中，哪个抗噪能力最强？哪个对采样不敏感？

为什么LR的输入特征一般是离散的而不是连续的？

在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：

    离散特征的增加和减少都很容易，易于模型的快速迭代；稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。

   
   
逻辑回归比线性回归要好。两者都属于广义线性模型。逻辑回归的鲁棒性比线性回归要好。
    逻辑回归是最大熵对应为二类时的特殊情况，也就是说，当逻辑回归扩展为多类别的时候，就是最大熵模型。

最大熵原理：学习概率模型的时候，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。
